---
bg: "joker.jpg"
layout: post
title:  "2019年终总结"
crawlertitle: "总结一下，做的更好"
summary: "这一年的最后，有点焦虑"
date:   2020-01-01 10:21:47 +0700
cataname: 一段时间，一些总结
category: life/2020-01-01
tags: ['life-工作总结']
author: Roderick
---
`很快又到了年末，很焦虑...`

又到了年终做回顾的时候了。  
想想年初，拟定了很多学习计划，很多目标，怀着满腔热血。  
然而，到了这个时刻，突然觉得有点愧对自己，也愧对别人对自己的期望，至少在我看来是这样的。  
简单回顾了一下19年的事迹：  
**工作上：**  
***Q1： 主要还是业务单子比较多。而且查问题花费的时间比较多***  
1.业务单：  
点播业务：其实做的大功能并没有，只是一些比较零散的功能。
聊天室和直播开发：主要还是聊天室吧，维护一些socket消息的方法，和ppt裁剪功能，接口编写。
2.大数据：  
(1)主要还是在功能设计上，讨论viewlog的实时计算和离线复算逻辑  
(2)编写spark读取kafka并落盘hdfs的demo，并且针对可靠性（节点恢复，作业重启），性能方面做了测试  
(3)一些方案在实施过程中不断地踩坑，并且做了多次调研。  

***Q2： 大数据的业务占了比较大的比重***  
1.业务单：(这一期经常要排查ppt的问题，最后有提出使用sei来解决问题)  
点播业务：完成sprint的日常开发，设计银河实时播放次数的针对性方案，排查一些日常问题，做一些排查工具给support  
聊天室和直播开发：修复ppt不同步的问题，裁剪支持多白板  
2.大数据：  
(1)对直播在线人数统计和详单汇总做了进一步的设计和技术选型，在编写代码过程中不断优化和调整方案，基本上方案已经落地。    
(2)调研hbase的性能以及使用，设计ods的rowkey，分区方案，实现详单入hbase的功能。  
(3)使用窗体函数实现实时在线人数的汇总统计，将结果入库mysql，调整spark作业的jvm内存参数，gc收集器，spark executor的内存分配参数，提高执行性能。  
(4)在试运行和测试阶段，排查和修复一系列问题，比如checkpoint文件引起ss程序启动失败，hbase分区数据分配不均衡，rowkey的结构调整优化，spark程序out of memory问题排查，spark gc频度异常等问题。    
(5)维护测试环境和正式环境的cdh环境，调整各个组件的内存分配保证其正常运行，排查每个服务器的ntp不同步问题。  

***Q3： 大数据的业务占了比较大的比重***  
1.业务单：
点播业务：实现了点播上传sdk的开发，sprint日常任务开发，日常问题排查  
聊天室和直播开发：设计了直播回放ppt不同步的SEI修正方案以及实现了相关的开发  
2.大数据：  
(1)完善直播在线人数统计的架构设计，优化实时的统计方式，计划使用kafka来做中间数据。（还未实践）  
(2)讨论重新设计高级分析底层数据模型，经过多次修改，确定了最后的实现方案。  
(3)讨论hbase存储viewlog详单的设计，针对热点，查询效率，分裂等问题，合理设计了rowkey以及使用了索引表的策略。  
(4)负责maxcompute中间数据表的作业实现，设计好观看区间的汇总方法以及相关的数据测试校验。  
(5)讨论热点的数据结构设计，最终使用线段树来做数据结构。  
(6)编写高级分析-观众分析的MapReduce作业程序，并且测试数据处理结果。  
(7)参与dmp底层框架的搭建，编写详单，视频分析，观众分析的输出接口。  
(8)参与maxcompute存储和计算的性能优化，成本降低等实现。  
(9)了解airflow工作流的实现，计划重新整理所有作业脚本以及工作流配置的项目组织结构。  

***Q4： 大数据的业务占了比较大的比重***  
1.业务单：  
点播业务：一些细小功能的调整，点播运营中心整个系统的编写。    
聊天室和直播开发：修复sei的bug，排查问题。  
2.大数据：  
(1)处理几个后台系统的日志的采集，编写logstash代码录入ES  
(2)旧版viewlog回填的程序改造成python脚本程序，加入airflow脚本节点，接入工作流的执行流程中  
(3)编写python脚本定期将网宿和阿里的目录带宽信息写入到es中，并将定时任务加入airflow的管理  
(4)原中山机房zookeeper与广州机房CDH集群zookeeper合并，迁移kafka节点到CDH的zk集群中  
(5)编写点直播rtas的发布脚本，统一airflow脚本时间参数的时区  
(6)优化直播rtas功能，异步写redis和发kafka avro消息，并且做功能和性能测试  
(7)GET大会的相关接口以及页面对接  
(8)日常问题的排查  

***工作内容的总结***
1.总的来说，前半段时间做的事情比较有价值，贴合我的发展目标，而且学的东西特别多，而后半段时间，虽然也学到不少，但是有点偏移了我们的工作重点。
2.Q2，Q3的工作饱和度比较高，特别是Q3完成了整个高级分析的功能，而且目前来说口碑不错。  
3.Q4是我最不满意的一个季度，做的功能并没有按预期的有所大进展，拖缓了实时计算这块的开发进度。   
4.有时还是得帮忙去排查业务方面的问题也会对我的可用工时造成一定的影响。  

这一整年其实能拿得出手的也就是高级分析和airflow的调度功能了...  

***问题总结和改进***
1.问题主要还是效率问题，有以下几点原因：  
(1)问题排查：有时一个问题的排查就需要耗费一天或者几个小时，而且切换工作内容需要一定的时间
(2)个人问题：首先，自己的功力还是不够扎实，看到案例还是不够多，一些方案没有足够好的想法和方向，排查问题的时候没有找对方向，开发的时候急于求成，没有系统的去看官方文档就实操，其次是状态问题，这几个sprint的状态确实不好，回到家索性就躺着了，没有半点想把问题拿起来想想应该怎么做。周末浪费了比较多的时间。  
2.项目进展问题，其实我们的主线还是要完成直播的实时统计和离线统计：  
(1)工具的使用上欠缺文档和实战经验，structured streaming的文档是实施还是比较少的。  
(2)刚好有个高级分析的功能需要紧急上线，导致实时统计被延后。
(3)效率问题导致进度缓慢。  
3.改进：  
(1)状态要调整好，卸载手机游戏，就算状态不佳，也不要玩游戏，可以去打打球，及时调整自己。  
(2)平时多看官方文档，不要只顾着将百度出来的瑕疵demo就拷下来用了。  
(3)多逛逛技术论坛，多关注一些比较实用的技术以及一些实际案例。  
(4)做好笔记，将平常和健哥沟通的一些细节都记录下来，多想多思考，不要问傻逼问题。  
(5)遇到问题不要急着下定论，要有足够的证明！！不然很容易打脸。多查下相关资料(官方文档，不要只百度)  

**生活上：**  
1.首先恭喜我下结婚啦，而且2020年还会迎来我的可爱宝宝。  
2.说好的月薪涨到2w，哎，遥遥无期。。辜负了老婆对我的期望。  
3.房子，户口那些基本定下来了，后面就等着收楼了，真的挺怕偷工减料。。  
4.说好的减肥。。一直没减下来，现在还是150多斤，哎。。。  



**2020的目标**
1.2020年估计得做一下准备吧，有空还是要多刷刷面试题，然后找到机会就跑路吧，当前比较重要的事情还是要提升自己的能力，当然面试技巧也要练好，起码面试这一关要过。。争取找到一个月薪2w的工作    
2.能够做到给我一个场景，我能够设计一套架构出来解决问题，并且可解决问题的。  
3.减肥工作还是要做的。。  
