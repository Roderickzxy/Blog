---
layout: post
title:  "hadoop-hdfs的总结"
crawlertitle: "关于hdfs"
summary: "在apache官网阅读hadoop之hdfs的一点小总结"
date:   2018-02-06 01:04:56 +0700
cataname: 积累，等待，蜕变
category: tech/2018-02-06
tags: 'tech-大数据'
author: Roderick
---
本文为阅读hadoop官网 [hdfs资料](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html "hdfs资料") 关于hdfs的架构，并做了一点记录，记录并不是特别多，只是单纯记录一下一些个人觉得需要标记的点。

## hdfs的架构 ##  
[![attache1]({{ site.article_attachedimages | relative_url }}/tech/article7-attache1.png)]({{ site.article_attachedimages | relative_url }}/article7-attache1.png)  
采用了master/salves的架构，其实master就是namenode，salves是多个datanodes

## 机架感知（rack-aware） ##  
作用：改进数据可靠性，可用性，网络带宽利用率。  
默认未优化的处理方式：将每个block副本存放于不同机架上  
一般情况（副本系数为3）： 2个同机架不同datanode，一个不同机架  
当副本系数大于3，则每个机架的副本数不能超过（副本数-1）/机架数+2  

## 安全模式 ##
NameNode启动后，通过心跳检测DataNode上的数据块的副本系数，超过N为安全，有M%以上的DataNode满足，则HDFS退出安全模式，并陆续将不安全的块处理为安全（复制新的副本）

## Editlog和FsImage ##
前者保存修改元数据的操作，后者保存命名空间，数据块-文件映射，文件属性等数据。  
checkpoint => NameNode启动后，FsImage从磁盘加载到内存，使用Editlog的事务操作修改FsImage，保存到磁盘，再删除旧的Editlog。

## 块报告 ##
DataNode启动后，自动扫描本地文件对应的所有块列表到NameNode上

## 通讯协议 ##
Tcp/Ip

## 常见错误 ##
1. NameNode出错
2. DataNode出错
3. 网络割裂

## 磁盘数据错误 ##
NameNode检测不到某DataNode的心跳，认为是宕机，不会再有io请求复制他们，在该节点上的数据会失效，引起副本系数下降，低于N时，启动了操作。  
因此引起复制有几个原因：  
1. 某DataNode失效
2. 某副本损坏
3. 某DataNode磁盘坏了
4. 文件副本系数被调低

## 集群均衡 ##
将无/空间不足的DataNode上的数据搬迁到空闲节点上

## 数据完整性 ##
客户端获得文件，会检验DataNode获得的数据与相应校验和文件的校验总和是否匹配，不匹配则从其他DataNode获取副本。  

## 元数据磁盘错误 ##
NameNode机器故障，需要手动干预，Editlog与FsImage损坏，会导致整个HDFS实例失效，NameNode可以维护多个Editlog和FsImage副本。

## HA（High Availablity） ##
1. NFS分享存储
2. QJM（Quorum Journal Manager）